{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1 :\n",
    "\n",
    "### 1.Building the Model\n",
    "__________\n",
    "**1.1) Build an MLP  and choose the values of $h^1$ and $h^2$ such that the total number of parameters (including biases) falls within the range of [0.5M, 1.0M].**\n",
    "\n",
    "The model is implemented within the NN class below.\n",
    "\n",
    "Given that the input size is 784 and we have 10 classes, we estimaed the size of each hidden layer as follow:\n",
    "\n",
    "- first hidden layer: 500 units\n",
    "- second hidden layer: 400 units\n",
    "\n",
    "The total number of parameters in our model with these settings is: $(784+1)*500 + (500+1)*400 + (400+1)*10 = 596910$\n",
    "\n",
    "\n",
    "**1.2) Implement the forward and backward propagation of the MLP in numpy without using any of the deep learning frameworks that provides automatic differentiation.**\n",
    "\n",
    "Our algorithm implements minibatch gradient descent, which allows us to save a lot of computation thanks to numpy's optimizations for matrix operations (we can use 1-example stochastic gradient descent by specifying batch_size = 1).\n",
    "\n",
    "We implemented the forward and backward propagation using matrices to represent the minibatches and the neural network parameters. This way, we avoid using looped sums and replace them by numpy matrix operations.\n",
    "\n",
    "We have also let to the user the possibility to use biases or not.\n",
    "\n",
    "In our implementation, all matrices are transposed compared to the course notations. This has to be highlighted because it changes the order of all matrix operations.\n",
    "\n",
    "#### Forward:\n",
    "Each batch is represented by a $\\mbox{batch_size} \\times 784$ matrix. It can be treated as the output $H_0$ of an imaginary layer with index $0$.\n",
    "\n",
    "For each hidden layer $i$ within $1\\leq i \\leq L$, we compute the preactivations matrix as $ A_{i} = H_{i-1}W_{i} + b_{i}$, with the following dimensions: \n",
    "\n",
    "- $A_i$ : the preactivations matrix of dimensions $\\mbox{batch_size} \\times h^{i}$\n",
    "- $H_{i-1}$ : the postactivations matrix of dimensions $\\mbox{batch_size} \\times h^{i-1}$\n",
    "- $W_{i}$ : the weights matrix of dimensions $h^{i-1} \\times h^{i}$ ($h^i$ being the number of units of the $i^{th}$ layer)\n",
    "- $b_{i}$: the biases matrix of dimensions $1 \\times h^{i}$\n",
    "\n",
    "As we can see, $H_{i-1}W_{i}$ and $b_{i}$ don't have the same first dimension, but thanks to the broadcast property provided by numpy, this is not an issue.\n",
    "\n",
    "After using this linear transformation, we apply an activation function (for example ReLU) on $A_{i}$, which gives us $H_{i} = \\mbox{activation}(A_{i})$.\n",
    "\n",
    "The only exception is the output layer, which has a different activation function (softmax) that defines the outputs $H_{L+1}$ as a $batch\\_size \\times 10$ matrix of $batch\\_size$ sets of total probabilities over the $10$ possible labels.\n",
    "\n",
    "#### Backward:\n",
    "\n",
    "We have implemented the backpropagation algorithm as follows:\n",
    "\n",
    "The preactivation gradients of the output layer $L+1$ are represented by the $batch\\_size \\times 10$ matrix $\\nabla A_{L+1}$, which is calculated according to:\n",
    "\n",
    "$$\n",
    "\\nabla A_{L+1} = -(\\mbox{true labels} - H_{L+1})\n",
    "$$\n",
    "\n",
    "(The 'true labels' matrix is a one-hot encoding of the real class of each example of the minibatch)\n",
    "\n",
    "Then for each layer $i$ starting from $L+1$ to $1$:\n",
    "\n",
    "- The weights gradients matrix is computed as:\n",
    "\n",
    "$$\n",
    "\\nabla W_{i} = \\frac{H_{i-1}^T \\nabla A_i}{\\mbox{batch_size}}\n",
    "$$\n",
    "\n",
    "This operation saves us a lot of computation and memory thanks to optimized matrix operations, as it computes at once the element-wise mean over the minibatch of the $\\mbox{batch_size}$ matrices of dimensions $h^{i-1} \\times h^{i}$ that would have been computed if we had considered each example separately. Indeed the matrix-product\n",
    "\n",
    "$$\n",
    "\\underset{(h^{i-1} \\times \\mbox{batch_size})}{H_{i-1}^T} \\underset{(\\mbox{batch_size} \\times h^{i})}{\\nabla A_i}\n",
    "$$\n",
    "\n",
    "is the element-wise sum of the $\\mbox{batch_size}$ matrices obtained for each example of the minibatch by the vector-product\n",
    "\n",
    "$$\n",
    "\\underset{(h^{i-1} \\times 1)}{h_{i-1}^T} \\underset{(1 \\times h^{i})}{\\nabla a_i}\n",
    "$$\n",
    "\n",
    "presented in the course. Dividing by $\\mbox{batch_size}$ gives us directly the average that has to be used for the upcoming update.\n",
    "\n",
    "- Similarly, the biases gradients matrix is computed as:\n",
    "\n",
    "$$\n",
    "\\nabla db_i = \\mbox{mean over batch dimension}(\\nabla A_i)\n",
    "$$\n",
    "\n",
    "which gives us a $1 \\times h^{i}$ vector of the mean of the biases gradients over the minibatch, homogeneous to the $b_i$ vector as we have seen before.\n",
    "\n",
    "- If the layer $i$ is not the layer $1$, we also need to compute $\\nabla H_{i-1}$ and $\\nabla A_{i-1}$ as follows:\n",
    "\n",
    "$$\n",
    "\\nabla H_{i-1} = \\nabla A_i \\nabla W_i^T\n",
    "\\\\\n",
    "\\nabla A_{i-1} = \\nabla H_{i-1} \\odot \\mbox{activation}(A_{i-1})\n",
    "$$\n",
    "\n",
    "so we can retropropagate gradients to the previous ($i-1$) layer and compute $\\nabla W_{i-1}$ and $\\nabla b_{i-1}$.\n",
    "\n",
    "\n",
    "**1.3) Train the MLP using the probability loss ($\\textit{cross entropy}$) as training criterion. We minimize this criterion to optimize the model parameters using $\\textit{stochastic gradient descent}$.**\n",
    "\n",
    "Our algorithm minimizes the cross entropy, estimated by:\n",
    "\n",
    "$$\n",
    "- \\frac{1}{N}\\sum_{i=1}^{N} \\mbox{true labels} * \\mbox{log}(\\mbox{prediction})\n",
    "$$\n",
    "\n",
    "Therefore, we use this loss function rather than accuracy to define our best model, and we keep this model in the bestWeights attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This part of the code implements live plotting of the train and validation loss and accuracy:\n",
    "from IPython.display import clear_output\n",
    "from matplotlib import pyplot as plt\n",
    "import collections\n",
    "%matplotlib inline\n",
    "\n",
    "def live_plot(data_dict1, title1, data_dict2, title2, figsize=(7,5), bestEpoch=0):\n",
    "    clear_output(wait=True)\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.subplot(1,2,1)\n",
    "    for label,data in data_dict1.items():\n",
    "        plt.plot(data, label=label)\n",
    "        if label == 'validation accuracy':\n",
    "            plt.plot(bestEpoch, data[bestEpoch], \"ro\")\n",
    "    plt.title(title1)\n",
    "    plt.grid(True)\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(loc='center left')\n",
    "    plt.subplot(1,2,2)\n",
    "    for label,data in data_dict2.items():\n",
    "        plt.plot(data, label=label)\n",
    "        if label == 'validation loss':\n",
    "            plt.plot(bestEpoch, data[bestEpoch], \"ro\")\n",
    "    plt.title(title2)\n",
    "    plt.grid(True)\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(loc='center left')\n",
    "    plt.show();\n",
    "\n",
    "# This part implements the NN:\n",
    "import numpy as np\n",
    "import pickle\n",
    "import copy\n",
    "import time\n",
    "\n",
    "\"\"\"MLP class :\n",
    "\n",
    "The model implemented as follows :\n",
    "Each layers is represented by a b vector (biases) and a W matrix (weights)\n",
    "These are referenced by the weights dictionary. The format is :\n",
    "self.weights[f\"X{n}\"] where X = b, W\n",
    "NB : In our implementation, all matrices are transposed compared to the class notations\n",
    "\"\"\"\n",
    "class NN(object):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 hidden_dims=(1024, 2048),   # dimensions of each hidden layers\n",
    "                 n_hidden=2,                 # number of hidden layers\n",
    "                 mode='train',               # current mode : train/test\n",
    "                 datapath=None,              # path where to find the .pkl file\n",
    "                 model_path=None,            # path where to save/load the model \n",
    "                 epsilon = 1e-6,             # for cross entropy calculus stability : log(x) = log(epsilon) if x < epsilon\n",
    "                 lr = 1e-1,                  # learning rate\n",
    "                 n_epochs = 1000,            # max number of epochs\n",
    "                 batch_size = 1000,          # batch size for training\n",
    "                 compute_biases = True,      # whether biases are used or not\n",
    "                 seed = None,                # seed for reproducibility\n",
    "                 activation = \"relu\",        # activation function\n",
    "                 init_method=\"glorot\"):      # initialization method\n",
    "        \"\"\"\n",
    "        - method: (string) - initializes the weight matrices\n",
    "            -> \"zero\" for a Zero initialisation of the weights\n",
    "            -> \"normal\" for a Normal initialisation of the weights\n",
    "            -> \"glorot\" for a Uniform initialisation of the weights\n",
    "        \"\"\"\n",
    "        assert len(hidden_dims) == n_hidden, \"Hidden dims mismatch!\"\n",
    "        \n",
    "        self.hidden_dims = hidden_dims\n",
    "        self.n_hidden = n_hidden\n",
    "        self.mode = mode\n",
    "        self.datapath = datapath\n",
    "        self.model_path = model_path\n",
    "        self.epsilon = epsilon\n",
    "        self.lr = lr\n",
    "        self.n_epochs = n_epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.compute_biases = compute_biases\n",
    "        self.init_method = init_method\n",
    "        self.seed = seed\n",
    "        self.activation_str = activation\n",
    "        \n",
    "        self.dataplot1 = collections.defaultdict(list) # history of the train and validation accuracies\n",
    "        self.dataplot2 = collections.defaultdict(list) # history of the train and validation losses\n",
    "        \n",
    "        self.bestValLoss = np.Infinity # min value of the validation loss\n",
    "        self.bestEpoch = 0 # epoch where we reached the min value of the validation loss\n",
    "        self.bestWeights = None # optimal weights dictionary (contains biases when compute_biases=True)\n",
    "        \n",
    "        # train, validation and test sets :\n",
    "        if datapath.lower().endswith(\".npy\"):\n",
    "            self.tr, self.va, self.te = np.load(open(datapath, \"rb\"))\n",
    "        elif datapath.lower().endswith(\".pkl\"):\n",
    "            u = pickle._Unpickler(open(datapath, 'rb'))\n",
    "            u.encoding = 'latin1'\n",
    "            self.tr, self.va, self.te = u.load()\n",
    "        else:\n",
    "            raise Exception(\"Unknown data source type!\")\n",
    "    \n",
    "    def initialize_weights(self, dims):\n",
    "        \"\"\"\n",
    "        Initializes the weights and biases according to the specified method :\n",
    "        - dims: (list of two integers) - the size of input/output layers\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        if self.seed is not None:\n",
    "            np.random.seed(self.seed)\n",
    "        if self.mode == \"train\":\n",
    "            self.weights = {}\n",
    "            all_dims = [dims[0]] + list(self.hidden_dims) + [dims[1]]\n",
    "            #print(\"Layers dimensions are : \", all_dims)\n",
    "            for layer_n in range(1, self.n_hidden + 2):\n",
    "                if self.init_method == \"zero\":\n",
    "                    self.weights[f\"W{layer_n}\"] = np.zeros(shape=(all_dims[layer_n - 1],all_dims[layer_n])).astype('float64')\n",
    "                elif self.init_method == \"normal\":\n",
    "                    #Be aware of the error you get \"true divide\", can be solved by dividing by dim_layer[n-1] \n",
    "                    self.weights[f\"W{layer_n}\"] = np.random.normal(loc=0.0, scale=1.0, size=(all_dims[layer_n - 1],\n",
    "                                                                                             all_dims[layer_n])).astype('float64')/all_dims[layer_n-1]\n",
    "                elif self.init_method == \"glorot\":\n",
    "                    b = np.sqrt(6.0/(all_dims[layer_n]+all_dims[layer_n-1]))\n",
    "                    self.weights[f\"W{layer_n}\"] = np.random.uniform(low=-b, high=b, size=(all_dims[layer_n - 1],\n",
    "                                                                                            all_dims[layer_n])).astype('float64')\n",
    "                else:\n",
    "                    raise Exception(\"The provided name for the initialization method is invalid.\")\n",
    "                \n",
    "                if self.compute_biases:\n",
    "                    self.weights[f\"b{layer_n}\"] = np.zeros((1, all_dims[layer_n]))\n",
    "                    \n",
    "        elif self.mode == \"test\": # test mode is to load the weights of an existing model\n",
    "            self.weights = np.load(self.model_path)\n",
    "        else:\n",
    "            raise Exception(\"Unknown Mode!\")\n",
    "    \n",
    "    def relu(self,x, prime=False):# Prime for Step function, else ReLu\n",
    "        if prime:\n",
    "            return x > 0\n",
    "        return np.maximum(0, x)\n",
    "    \n",
    "    def sigmoid(self,x, prime=False):\n",
    "        if prime:\n",
    "            return self.sigmoid(x)*(1 -  self.sigmoid(x))\n",
    "        return 1/(1 + np.exp(-x))\n",
    "    \n",
    "    def tanh(self,x, prime=False):\n",
    "        if prime:\n",
    "            return 1 -  np.power(self.tanh(x),2)\n",
    "        return np.tanh(x)\n",
    "    \n",
    "    def activation(self, input_, prime=False):  \n",
    "        if self.activation_str == \"relu\":\n",
    "            return self.relu(input_,prime)\n",
    "        elif self.activation_str == \"sigmoid\":\n",
    "            return self.sigmoid(input_,prime)\n",
    "        elif self.activation_str == \"tanh\":\n",
    "            return self.tanh(input_,prime)\n",
    "        else:\n",
    "            raise Exception(\"Unsupported activation!\")\n",
    "\n",
    "    def softmax(self, input_):  # Computes the softmax of the input\n",
    "        \"\"\"\n",
    "        Documentation\n",
    "        \"\"\"\n",
    "        Z = np.exp(input_ - np.max(input_)) # softmax(x-C) = softmax(x) (stability)\n",
    "        return Z / np.sum(Z, axis=1, keepdims=True)\n",
    "    \n",
    "    def forward(self, input_):  # Forward propagation : computes the outputs (cache) from the input\n",
    "        \"\"\"\n",
    "        Documentation\n",
    "        \"\"\"\n",
    "        cache = {\"H0\": input_}\n",
    "        for layer in range(1, self.n_hidden + 1):\n",
    "            if self.compute_biases:\n",
    "                cache[f\"A{layer}\"] = cache[f\"H{layer-1}\"] @ self.weights[f\"W{layer}\"] + self.weights[f\"b{layer}\"]\n",
    "            else:\n",
    "                cache[f\"A{layer}\"] = cache[f\"H{layer-1}\"] @ self.weights[f\"W{layer}\"]\n",
    "            cache[f\"H{layer}\"] = self.activation(cache[f\"A{layer}\"])\n",
    "\n",
    "        layer = self.n_hidden + 1\n",
    "        if self.compute_biases:\n",
    "            cache[f\"A{layer}\"] = cache[f\"H{layer-1}\"] @ self.weights[f\"W{layer}\"] + self.weights[f\"b{layer}\"]\n",
    "        else:\n",
    "            cache[f\"A{layer}\"] = cache[f\"H{layer-1}\"] @ self.weights[f\"W{layer}\"]\n",
    "        cache[f\"H{layer}\"] = self.softmax(cache[f\"A{layer}\"]) # softmax on last layer\n",
    "        return cache\n",
    "    \n",
    "    def backward(self, cache, labels):  # Backward propagation : computes the gradients from the outputs (cache)\n",
    "        \"\"\"\n",
    "        Documentation\n",
    "        \"\"\"\n",
    "        output = cache[f\"H{self.n_hidden+1}\"]\n",
    "        grads = {f\"dA{self.n_hidden+1}\": - (labels - output)}\n",
    "        for layer in range(self.n_hidden + 1, 0, -1):\n",
    "            # the following operation averages at once all the matrices\n",
    "            # that we would have calculated for each example of the minibatch if we had not represented it in matrix form :\n",
    "            grads[f\"dW{layer}\"] = cache[f\"H{layer-1}\"].T @ grads[f\"dA{layer}\"] / self.batch_size\n",
    "            # we need to do the same for the biases gradients :\n",
    "            if self.compute_biases:\n",
    "                grads[f\"db{layer}\"] = np.mean(grads[f\"dA{layer}\"], axis=0, keepdims=True)\n",
    "            if layer > 1:\n",
    "                grads[f\"dH{layer-1}\"] = grads[f\"dA{layer}\"] @ self.weights[f\"W{layer}\"].T\n",
    "                grads[f\"dA{layer-1}\"] = grads[f\"dH{layer-1}\"] * self.activation(cache[f\"A{layer-1}\"], prime=True)\n",
    "        return grads\n",
    "    \n",
    "    def update(self, grads):  # To update the weights and the biases\n",
    "        \"\"\"\n",
    "        Documentation\n",
    "        \"\"\"\n",
    "        for layer in range(1, self.n_hidden + 1):\n",
    "            self.weights[f\"W{layer}\"] = self.weights[f\"W{layer}\"] - self.lr * grads[f\"dW{layer}\"]\n",
    "            if self.compute_biases:\n",
    "                self.weights[f\"b{layer}\"] = self.weights[f\"b{layer}\"] - self.lr * grads[f\"db{layer}\"]\n",
    "    \n",
    "    def loss(self, prediction, labels):  # Computes the cross entropy\n",
    "        \"\"\"\n",
    "        Documentation\n",
    "        \"\"\"\n",
    "        prediction[np.where(prediction < self.epsilon)] = self.epsilon\n",
    "        prediction[np.where(prediction > 1 - self.epsilon)] = 1 - self.epsilon\n",
    "        return -1 * np.sum(labels * np.log(prediction)) / prediction.shape[0]\n",
    "    \n",
    "    def computeLossAndAccuracy(self, X, y):  # Stores the accuracy/loss of the train/validation sets\n",
    "        \"\"\"\n",
    "        Documentation\n",
    "        \"\"\"\n",
    "        on_y = self._one_hot(y)\n",
    "        vCache = self.forward(X)\n",
    "        vOut = np.argmax(vCache[f\"H{self.n_hidden + 1}\"], axis=1)\n",
    "        vAccuracy = np.mean(y == vOut)\n",
    "        vLoss = self.loss(vCache[f\"H{self.n_hidden+1}\"], on_y)\n",
    "        return vLoss, vAccuracy, vOut\n",
    "    \n",
    "    def _one_hot(self,y):\n",
    "        \"\"\"\n",
    "        Documentation\n",
    "        \"\"\"\n",
    "        _, y_train = self.tr\n",
    "        return np.eye(np.max(y_train) - np.min(y_train) + 1)[y]\n",
    "    \n",
    "    def train(self,show_graph = True, save_model = True):\n",
    "        \"\"\"\n",
    "        Documentation\n",
    "        \"\"\"\n",
    "        X_train, y_train = self.tr\n",
    "        y_onehot = self._one_hot(y_train)\n",
    "        dims = [X_train.shape[1], y_onehot.shape[1]]\n",
    "        self.initialize_weights(dims)\n",
    "        n_batches = int(np.ceil(X_train.shape[0] / self.batch_size))\n",
    "\n",
    "        for epoch in range(self.n_epochs):\n",
    "            predictedY = np.zeros_like(y_train)\n",
    "            for batch in range(n_batches):\n",
    "                minibatchX = X_train[self.batch_size * batch:self.batch_size * (batch + 1), :]\n",
    "                minibatchY = y_onehot[self.batch_size * batch:self.batch_size * (batch + 1), :]\n",
    "                cache = self.forward(minibatchX)\n",
    "                grads = self.backward(cache, minibatchY)\n",
    "                self.update(grads)\n",
    "                predictedY[self.batch_size * batch:self.batch_size * (batch + 1)] = np.argmax(\n",
    "                    cache[f\"H{self.n_hidden + 1}\"], axis=1)\n",
    "                \n",
    "            X_tr, y_tr = self.tr\n",
    "            trLoss, trAccuracy,_ = self.computeLossAndAccuracy(X_tr, y_tr)\n",
    "            X_val, y_val = self.va\n",
    "            valLoss, valAccuracy,_ = self.computeLossAndAccuracy(X_val, y_val)\n",
    "            \n",
    "            if valLoss < self.bestValLoss:\n",
    "                self.bestValLoss = valLoss\n",
    "                self.bestEpoch = epoch\n",
    "                self.bestWeights = copy.deepcopy(self.weights)\n",
    "            \n",
    "            self.dataplot1['train accuracy'].append(trAccuracy)\n",
    "            self.dataplot1['validation accuracy'].append(valAccuracy)\n",
    "            self.dataplot2['train loss'].append(trLoss)\n",
    "            self.dataplot2['validation loss'].append(valLoss)\n",
    "            if show_graph:\n",
    "                live_plot(self.dataplot1, \"Accuracy\", self.dataplot2, \"Loss\", (14,5), self.bestEpoch)\n",
    "        \n",
    "        if save_model:\n",
    "            # Save Best Model\n",
    "            if self.model_path is None:\n",
    "                string_hdims = \"-\".join(map(str,self.hidden_dims))\n",
    "                model_name = f\"best-model-init-{self.init_method}-lr-{self.lr}-hdims-{string_hdims}-batches-{self.batch_size}.npz\"\n",
    "                np.savez(model_name,**self.bestWeights)\n",
    "            else:\n",
    "                np.savez(self.model_path,**self.bestWeights)\n",
    "            \n",
    "        return self.dataplot1, self.dataplot2\n",
    "    \n",
    "    def test(self):\n",
    "        \"\"\"\n",
    "        Documentation\n",
    "        \"\"\"\n",
    "        X_te, y_te = self.te\n",
    "        vLoss, vAccuracy,_ = self.computeLossAndAccuracy(X_te, y_te)\n",
    "        print(f\"Test Accuracy:{vAccuracy}, Test Loss:{vLoss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the following questions, the architecture we chose is a 2-layer neural network of size $(500, 400)$. The batch size is $100$, and the learning rate is $0.5$, which we found converges very quickly with this setting.\n",
    "\n",
    "### 2. Initialization\n",
    "\n",
    "**2.1) Train the model for 10 epochs using the initialization methods and record the average loss measured on the training data at the end of each epoch (10 values for each setup).**\n",
    "\n",
    "**- Initialization with zeros:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAAFNCAYAAAA6tU9BAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzs3Xuc1lW58P/PJUdBQDyxDS1od5DTcHBQipQxxNJ2Wh5St+ahlGebael+2llPecjcT9u0yLLc5CEyK92apUValiP1Mw31QRTRPGEg5omDTkkKXL8/7sU04hxuYGCGmc/79ZoX973utdZ3fS9mZs11r/X93pGZSJIkSZJgm44egCRJkiR1FiZIkiRJklSYIEmSJElSYYIkSZIkSYUJkiRJkiQVJkiSJEmSVJggSZIkSVJhgiRVISLqI2J5RPTp6LFIktQeImJRROzf0eOQOhsTJKkNETEM2AdI4OAteNyeW+pYkiRJqjBBktp2HHAX8D3g+HWFEbFtRFwcEU9FxMqI+H1EbFtee09E3BkRKyJicUScUMrrI+KkJn2cEBG/b/I8I+LUiHgUeLSUfaP08VJE3BsR+zSp3yMiPh8Rj0fEy+X13SPi0oi4uOlJRMTNEfHpzREgSVLXEREnR8RjEbEsIm6KiDeV8oiIr0fEc2Xemx8Ro8trB0XEQ2Uuejoi/nfHnoW08UyQpLYdB1xTvt4XEUNK+UXAnsC7gR2A/wDWRsSbgV8C3wR2BsYB8zbgeB8C9gZGludzSx87AD8E/ici+pbXzgSOBg4CBgIfA/4GzAKOjohtACJiJ2Aq8KMNOXFJUvcSEe8F/i/wEWBX4Cngx+XlA4B9gXcA2wNHAi+W164A/ldmDgBGA7/dgsOW2pUJktSKiHgP8Bbgusy8F3gc+NeSeHwM+FRmPp2ZazLzzsz8O3AMcFtm/igzX8vMFzNzQxKk/5uZyzLzFYDM/EHpY3VmXgz0Ad5Z6p4EfCEzH8mK+0vdPwIrqSRFAEcB9Zn57CaGRNJGiogryzvvD7ZTf7eUVeqfr1d+TUQ8EhEPlmP2qrK/3SPi9ohYGBELIuJTLdQ7pKwczIuIe8rvyXWvHR8Rj5av40tZv4j4RUQ8XPr9SpP6J0TE86WveeutsF9Y6i+MiEsiIkp5fTm/dW12KeV9IuLasvJxd9keTUT0joirIuKBiLg/IurWi+H95TiXRUSPamLVxR0DXJmZ95U57XPAu0o8XwMGAHsAkZkLM/OZ0u41YGREDMzM5Zl5XweMXWoXJkhS644HfpWZL5TnPyxlOwF9qSRM69u9hfJqLW76JCL+vfyBsDIiVgCDyvHbOtYs4Njy+Fjg6k0Yk6RN9z3g/e3Y31eBjzZTfg2VP2DHANtSeSPldSLie00ThWI18O+ZOQKYBJwaESPXbwv8BhibmeOovFF0eelzB+AcKivgewHnRMTg0uaizNwDGA9MjogDm/R3bWaOK1/r+no3MBmoobIaMRGY0qTNMU3aPFfKPg4sz8y3AV8H/quUnwyQmWOAacDF61bXgY9k5thyjJ2BI5o53+7mTVRWjQDIzAYqq0RDM/O3wLeAS4FnI2JmRAwsVQ+jspvhqYi4IyLetYXHLbUbEySpBVG5nugjwJSI+EtE/AU4AxhLZdvBKuCfm2m6uIVygL8C/Zo8/6dm6mSTMewDfLaMY3Bmbk9lZSiqONYPgEMiYiwwAvhpC/UkbQGZOQdY1rQsIv65rGLcGxG/i4g9NqC/3wAvN1M+u6woJ/BHYLcq+3tm3bv+mfkysBAY2ky9htI3QH/+8TvrfcCvywr4cuDXwPsz82+ZeXtp+ypwXxVjSipvQvWmsmreC2hrBfwQKm8MAVwPTC2rTiOpJHWUZGoFUFuev1Tq9yzHSrSUys4JACKiP7Aj8DRAZl6SmXsCo6hstftMKZ+bmYcAu1CZb67bwuOW2o0JktSyDwFrqEyu48rXCOB3VK5LuhL4WkS8KSo3S3hXVG4Dfg2wf0R8JCJ6RsSOETGu9DkPOLRsOXkblXc8WzOAyru6zwM9I+JsKtcarXM5cH5EvL1cPFsTETsCZOYSKtcvXQ3csG7LnqROZSZwWvmD838D326vjsvWuo8Ct2xE22FUVnvubuH1D0fEw8AvqKwiQSWZaroCvoT1EqyI2B74ICVhKQ4rW/auj4jdATLzD8DtwDPl69bMXNikzVVle90X1229a3r8zFxN5c2kHYH7qbxZ1DMihlO5dnT3JmO6FXiOSrJ5fRuh6Yp6RUTfdV9UEpsTI2JcmdP+E7g7MxdFxMSI2Lt8b/2VyhuFa8o2xmMiYlBmvga8RGX+lLZKJkhSy44HrsrMP2fmX9Z9UdlecAxwFvAAlSRkGZXtHNtk5p+pbDP491I+j8qqE1S2fbxK5Z3QWVSSqdbcSuWGD3+isuVhFa//A+RrVCazX1GZkK6gsqVmnVlUttm4vU7qZCJiOyo3efmfiJgH/DeV1Wki4tCoXEO0/tetG3CIbwNzMvN3pc/3rbtuh8pHFlxenr8uCSrjugH4dJMVltfJzBvLlrkPAeeva9pc1Sb99qRyo5hLMvOJUnwzMCwza4DbKCtA5Q2kEVRWmoYC742IfUubY8p2uX3K17pthi0d/0oqydo9wAzgTipvPK07l/dRiXsf4L3NnW8XNxt4pcnXPsAXqXwPPENll8JRpe5A4LvAcipz0otUblgElf+HRRHxEvBv/GOLt7TViX+skkvqasofFD+g8gfI2o4ej9TdlZWZn2fm6HLtxiOZuesm9FcH/O/M/Jf1ys+hsgJ0aHM/+xHxPeB7mVm/Xnkv4OdUVmy+VuUYnqRyjdA0oC4z/1cp/28qN4f5UXl+JdCQmae30E8PYFlmDoqIzwB9M/P88trZwKrMvHC9NicAtZn5yZI8npuZfyjJ2F+AnXO9P3Qi4k7gpMx8aL3y44GJmfnJas5bUtflCpLURZU/dD4FXG5yJHU+ZXXmyYg4Aho/Y2ZsG83aFJU7wb0POHpDfvbLVrUrgIWtJUcR8bZ129oiYgKVa3depLLifUBEDC43ZziglBERX6Zyg5lPr9dX0+TwYCrXPQH8mcr1nz3L77IpwMLyfKfSthfwL8C6uwLexD8+q+5w4LeZmWVLc//SZhqwOjMfiojt1h2/JFQHAQ9XGy9JXVfPjh6ApPYXESOobCe5Hzixg4cjCYiIHwF1wE4RsYTKHd+OAb4TEV+gciOCH1P5ua2mv99RuVvddqW/j2fmrcBlVLY//aHkMT/JzC9V0eVkKtukHijb8AA+n5mzI+LfADLzMip3KzsuIl6jsiXryLJKsywizqey7RjgS5m5LCJ2A/4PleTjvjKmb5U71p0eEQdT2fK2DDihtL2eyna3B6hsk7slM28uic6tJTnqQWVb3ndLmyuAqyPisdLXum1hu5Q2a6ncaGDdlrz+wE3lOpseVD6357Iq4iSpi3OLnSRJkiQVbrGTJEmSpMIESZIkSZKKLnEN0k477ZTDhg3b6PZ//etf6d+/f/sNqIsxPq0zPi0zNq3ravG59957X8jMnTt6HJ2R89TmZXxaZ3xaZ3xa1tViU+081SUSpGHDhnHPPfdsdPv6+nrq6urab0BdjPFpnfFpmbFpXVeLT0Q81dFj6KycpzYv49M649M649Oyrhabaucpt9hJkiRJUmGCJEmSJEmFCZIkSZIkFSZIkiRJklSYIEmSJElSYYIkSZIkSYUJkiRJkiQVVSVIEfH+iHgkIh6LiLOaeb1PRFxbXr87IoaV8t4RcVVEPBAR90dEXZM2R0bE/IhYEBEXNinfNyLui4jVEXH4Jp9ha665BoYNY8p73wvDhlWeS5IkSeq22kyQIqIHcClwIDASODoiRq5X7ePA8sx8G/B14L9K+ckAmTkGmAZcHBHbRMSOwFeBqZk5ChgSEVNLmz8DJwA/3JQTa9M118D06fDUU0QmPPVU5blJkiRJktRt9ayizl7AY5n5BEBE/Bg4BHioSZ1DgHPL4+uBb0VEUEmofgOQmc9FxAqgFkjgT5n5fGlzG3AY8JvMXFSOs3bjT6sK/+f/wN/+9vqyv/0NPnUSvLp5c7OtzbgVK+DJ7Tt6GJ2W8WmZsWldp4vPP42BA7/S0aOQJKlDVZMgDQUWN3m+BNi7pTqZuToiVgI7AvcDh5Skandgz/Lvb4E9yla8JcCHgN4bMvCImA5MBxgyZAj19fUb0pwpf/4z0Ux5vriKlStWbFBfXd2aNWtYYUxaZHxaZmxa19ni07B6CY9t4O9SSZK6mmoSpGbziCrrXAmMAO4BngLuBFZn5vKIOAW4Flhbyt9a7aABMnMmMBOgtrY26+rqNqQ5vPnNlW1164m3vIXtz/j/NqyvLq6+vp4Njm83YnxaZmxa19nisz2wW0cPQpKkDlbNTRqWUFn1WWc3YGlLdSKiJzAIWJaZqzPzjMwcl5mHUJl/HwXIzJszc+/MfBfwyLryLeaCC6Bfv9eX9etXKZckSZLULVWTIM0F3h4RwyOiN3AUcNN6dW4Cji+PDwd+m5kZEf0ioj9AREyjsnr0UHm+S/l3MPAJ4PJNPpsNccwxMHMmvOUtZAS85S2V58ccs0WHIUmSJKnzaHOLXbmm6JPArUAP4MrMXBARXwLuycybgCuAqyPiMWAZlSQKYBfg1nLDhaeBjzbp+hsRMbY8/lJm/gkgIiYCNwKDgQ9GxHnlTnft75hj4JhjuKOTbXORJEmS1DGquQaJzJwNzF6v7Owmj1cBRzTTbhHwzhb6PLqF8rm4DV6S1MlFxPZUdj+MpnLd7ccy8w8dOypJ0qaqKkGSJElv8A3glsw8vGxB79dWA0lS52eCJEnSBoqIgcC+VD7YnMx8FXi1I8ckSWof1dykQZIkvd5bgeeBqyLi/0XE5etuSiRJ2rq5giRJ0obrCUwATsvMuyPiG8BZwBfXVdjUDzRvqqGhYZPad3XGp3XGp3XGp2XdNTYmSJIkbbglwJLMvLs8v55KgtRokz/QvInO9qHCnY3xaZ3xaZ3xaVl3jY1b7CRJ2kCZ+RdgcUSsu1PrVOChDhySJKmduIIkSdLGOQ24ptzB7gngxA4ejySpHZggSZK0ETJzHlDb0eOQJLUvt9hJkiRJUmGCJEmSJEmFCZIkSZIkFSZIkiRJklSYIEmSJElSYYIkSZIkSYUJkiRJkiQVJkiSJEmSVJggSZIkSVJhgiRJkiRJhQmSJEmSJBUmSJIkSZJUmCBJkiRJUmGCJEmSJEmFCZIkSZIkFSZIkiRJklSYIEmSJElSYYIkSZIkSYUJkiRJkiQVJkiSJEmSVJggSZIkSVJhgiRJkiRJhQmSJEmSJBUmSJIkSZJUmCBJkiRJUmGCJEmSJEmFCZIkSZIkFSZIkiRJklSYIEmSJElSYYIkSZIkSYUJkiRJkiQVJkiSJEmSVJggSZIkSVJhgiRJkiRJhQmSJEmSJBUmSJIkSZJUVJUgRcT7I+KRiHgsIs5q5vU+EXFtef3uiBhWyntHxFUR8UBE3B8RdU3aHBkR8yNiQURc2FZfkiRJkrS5tZkgRUQP4FLgQGAkcHREjFyv2seB5Zn5NuDrwH+V8pMBMnMMMA24OCK2iYgdga8CUzNzFDAkIqa20ZckSZIkbVbVrCDtBTyWmU9k5qvAj4FD1qtzCDCrPL4emBoRQSWh+g1AZj4HrABqgbcCf8rM50ub24DD2uhLkiRJkjarahKkocDiJs+XlLJm62TmamAlsCNwP3BIRPSMiOHAnsDuwGPAHhExLCJ6Ah8q5a31JUmSJEmbVc8q6jS3epNV1rkSGAHcAzwF3AmszszlEXEKcC2wtpS/dQOOR0RMB6YDDBkyhPr6+jZPpCUNDQ2b1L6rMz6tMz4tMzatMz6SJHU+1SRIS/jH6g7AbsDSFuosKStCg4BlmZnAGesqRcSdwKMAmXkzcHMpnw6saa2v9QeVmTOBmQC1tbVZV1dXxak0r76+nk1p39UZn9YZn5YZm9YZH0mSOp9qttjNBd4eEcMjojdwFHDTenVuAo4vjw8HfpuZGRH9IqI/QERMo7J69FB5vkv5dzDwCeDy1vraqLOTJEmSpA3Q5gpSZq6OiE8CtwI9gCszc0FEfAm4JzNvAq4Aro6Ix6is9hxVmu8C3BoRa4GngY826fobETG2PP5SZv6pPG6pL0mSJEnarKrZYkdmzgZmr1d2dpPHq4Ajmmm3CHhnC30e3UJ5s31JkiRJ0uZW1QfFSpIkSVJ3YIIkSZIkSYUJkiRJkiQVJkiSJEmSVJggSZIkSVJR1V3sJEnS60XEIuBlKh90vjozazt2RJKk9mCCJEnSxtsvM1/o6EFIktqPW+wkSZIkqTBBkiRp4yTwq4i4NyKmd/RgJEntwy12kiRtnMmZuTQidgF+HREPZ+acdS+WpGk6wJAhQ6ivr9/oAzU0NGxS+67O+LTO+LTO+LSsu8bGBEmSpI2QmUvLv89FxI3AXsCcJq/PBGYC1NbWZl1d3UYfq76+nk1p39UZn9YZn9YZn5Z119i4xU6SpA0UEf0jYsC6x8ABwIMdOypJUntwBUmSpA03BLgxIqAyl/4wM2/p2CFJktqDCZIkSRsoM58Axnb0OCRJ7c8tdpIkSZJUmCBJkiRJUmGCJEmSJEmFCZIkSZIkFSZIkiRJklSYIEmSJElSYYIkSZIkSYUJkiRJkiQVJkiSJEmSVJggSZIkSVJhgiRJkiRJhQmSJEmSJBUmSJIkSZJUmCBJkiRJUmGCJEmSJEmFCZIkSZIkFSZIkiRJklSYIEmSJElSYYIkSZIkSYUJkiRJkiQVJkiSJEmSVJggSZIkSVJhgiRJkiRJhQmSJEmSJBUmSJIkSZJUmCBJkiRJUmGCJEmSJEmFCZIkSZIkFSZIkiRJklSYIEmSJElSYYIkSZIkSUVVCVJEvD8iHomIxyLirGZe7xMR15bX746IYaW8d0RcFREPRMT9EVHXpM3RpXx+RNwSETuV8rER8Yfy2s0RMbBdzlSSJEmS2tBmghQRPYBLgQOBkcDRETFyvWofB5Zn5tuArwP/VcpPBsjMMcA04OKI2CYiegLfAPbLzBpgPvDJ0uZy4KzS5kbgM5twfpIkSZJUtWpWkPYCHsvMJzLzVeDHwCHr1TkEmFUeXw9MjYigklD9BiAznwNWALVAlK/+pd5AYGlp/05gTnn8a+CwjTgvSZIkSdpgPauoMxRY3OT5EmDvlupk5uqIWAnsCNwPHBIRPwZ2B/YEds/MP0bEKcADwF+BR4FTS18PAgcDPwOOKO022GuvvcaSJUtYtWpVm3UHDRrEwoULN+Yw3UJXiU/fvn3Zbbfd6NWrV0cPRZKcp9rR5o6P84fUvVSTIEUzZVllnSuBEcA9wFPAncDqiOgFnAKMB54Avgl8Dvgy8DHgkog4G7gJeLXZQUVMB6YDDBkyhPr6+te9vt122zFkyBCGDh1KZZGqZWvWrKFHjx6t1unOukJ8MpOVK1dy//3309DQ0K59NzQ0vOH7TxXGpnXGp3tbsmQJAwYMYNiwYW3OUy+//DIDBgzYQiPb+mzO+GQmL774IkuWLGH48OGb5RiSOpdqEqQlvH4VZzf+sR1u/TpLyvVFg4BlmZnAGesqRcSdVFaLxgFk5uOl/DrgrFL2MHBAKX8H8IHmBpWZM4GZALW1tVlXV/e61xcuXMhuu+3W5qQDTjxt6SrxGTBgAA0NDdTW1rZrv/X19az//acKY9M649O9rVq1qqrkSB0rIthxxx15/vnnO3ookraQaq5Bmgu8PSKGR0Rv4CgqKztN3QQcXx4fDvw2MzMi+kVEf4CImAaszsyHgKeBkRGxc2kzDVhY6u1S/t0G+AJw2caenJOOmvL7QVJn4++lrYP/T1L30uYKUrmm6JPArUAP4MrMXBARXwLuycybgCuAqyPiMWAZlSQKYBfg1ohYSyUp+mjpc2lEnAfMiYjXqGy/O6G0OToi1l2P9BPgqnY4T0mSJElqU1Wfg5SZszPzHZn5z5l5QSk7uyRHZOaqzDwiM9+WmXtl5hOlfFFmvjMzR2Tm/pn5VJM+LyvlNZn5wcx8sZR/oxzrHZl5Vtmmt9VZsWIF3/72tzeq7UEHHcSKFSvaeUSSJP3Dlpynzj33XC666KKNOpYkbWlVJUjacK1NPGvWrGm17ezZs9l+++03x7A2SWaydu3ajh6GJKkddMV5SpLagwnSZnLWWWfx+OOPM27cOD7zmc9QX1/Pfvvtx7/+678yZswYAD70oQ+x5557MmrUKGbOnNnYdtiwYbzwwgssWrSIESNGcPLJJzNq1CgOOOAAXnnllTcc6+abb2bvvfdm/Pjx7L///jz77LNA5Q5ZJ554ImPGjKGmpoYbbrgBgFtuuYUJEyYwduxYpk6dCrzx3b3Ro0ezaNEiFi1aRG1tLZ/4xCeYMGECixcv5pRTTqG2tpZRo0ZxzjnnNLaZO3cu7373uxk7dix77bUXL7/8Mvvssw/z5s1rrDN58mTmz5/fjpGWJG2MLTlPNTVv3jwmTZpETU0NH/7wh1m+fDkAl1xyCSNHjqSmpoajjqrs1L/jjjsYN24c48aNY/z48bz88subKRqS9A/V3MVuq3fezQt4aOlLLb6+MbexHvmmgZzzwVEtvv6Vr3yFBx98sDE5qK+v549//CMPPvhg421Cr7zySnbYYQdeeeUVJk6cyGGHHcaOO+74un4effRRfvSjH/Hd736Xj3zkI9xwww0ce+yxr6vznve8h7vuuouI4PLLL+fCCy/k4osv5vzzz2fQoEE88MADACxfvpznn3+ek08+mTlz5jB8+HCWLVvW5rk++uijzJo1q/GdxgsuuIAddtiBNWvWMHXqVObPn88ee+zBkUceybXXXsvEiRN56aWX2HbbbTnppJP43ve+x4wZM/jTn/7E3//+d2pqaqoPtCR1A119nmrquOOO45vf/CZTpkzh7LPP5rzzzmPGjBl85Stf4cknn6RPnz6N2/cuuugiLr30UiZPnkxDQwN9+/bdoBhI0sZwBWkL2muvvV73GQqXXHIJY8eOZdKkSSxevJhHH330DW2GDx/OuHHjANhzzz1ZtGjRG+osWbKE973vfYwZM4avfvWrLFiwAIDbbruNU089tbHe4MGDueuuu9h3330bx7HDDju0Oe43v/nNTJo0qfH5ddddx4QJExg/fjwLFizgoYce4pFHHmHXXXdl4sSJAAwcOJCePXtyxBFH8POf/5zXXnuNK6+8khNOOKHtQEmSOsTmmqfWWblyJStWrGDKlCkAHH/88cyZMweAmpoajjnmGH7wgx/Qs2fl/dvJkydz5plncskll7BixYrGcknanLrFb5rW3kGDLfc5P/379298XF9fz2233cYf/vAH+vXrR11dXbOfpt6nT5/Gxz169Gh268Jpp53GmWeeycEHH0x9fT3nnnsuULlmaP1bkzZXBtCzZ8/XXV/UdCz9+vVrfPzkk09y0UUXMXfuXAYPHswJJ5zAqlWrWuy3X79+TJs2jZ/97Gdcd9113HPPPc2FRpK6ta4+T1XjF7/4BXPmzOGmm27i/PPPZ8GCBZx11ll84AMfYPbs2UyaNInbbruNPfbYY6P6l6RquYK0mQwYMKDVvdIrV65k8ODB9OvXj4cffpi77rpro4+1cuVKhg4dCsCsWbMayw844AC+9a1vNT5fvnw573rXu7jjjjt48sknARq32A0bNoz77rsPgPvuu6/x9fW99NJL9O/fn0GDBvHss8/yy1/+EoA99tiDpUuXMnfuXKAyma9evRqAk046idNPP52JEydWtWIlSdr8tuQ8tc6gQYMYPHgwv/vd7wC4+uqrmTJlCmvXrmXx4sXst99+XHjhhaxYsYKGhgYef/xxxowZw2c/+1lqa2t5+OGHN3kMktQWE6TNZMcdd2Ty5MmMHj2az3zmM294/f3vfz+rV6+mpqaGL37xi6/bwrahzj33XI444gj22Wcfdtppp8byL3zhCyxfvpzRo0czduxYbr/9dnbeeWdmzpzJoYceytixYznyyCMBOOyww1i2bBnjxo3jO9/5Du94xzuaPdbYsWMZP348o0aN4mMf+xiTJ08GoHfv3lx77bWcdtppjB07lmnTpjW+07jnnnsycOBATjzxxI0+R0lS+9qS81RTs2bN4jOf+Qw1NTXMmzePs88+mzVr1nDssccyZswYxo8fzxlnnMH222/PjBkzGuewbbfdlgMPPLBdxiBJrYmt9GOGXqe2tjbX37q1cOFCRowYUVX7LbV1YWu1qfFZunQpdXV1PPzww2yzTcfm5BvyfVGt+vp66urq2rXPrsLYtK6rxSci7s3M2o4eR2fkPLV5bYn4bI75Y0vpar9r2pvxaVlXi02185QrSNqsvv/977P33ntzwQUXdHhyJElbnRdfhPnz2e6RR2D+/MpzSdJm1S1u0qCOc9xxx3Hcccd19DAkaevz4ovw1FOwdi0B8OqrlecA691qW5LUfkyQJEnaCBHRA7gHeDoz/6XdD/D009Dk7qIArF3L2j8v4u+vPt/uh9ua9cjklYY33km1Pb228i8s+M+TN+sxNpfBq1ez4E7/5GuJ8WlZZ4vNy9uPYNInvrvZj+OeJ0mSNs6ngIWbrfdXX222ONZs/dcOS1Jn1nlSQkmSthIRsRvwAeAC4MzNcpDevZtNkqJ3b7bd1c8CampL3KSh14pkxOd/v1mPsbl0tQvt25vxaVl3jY0rSJIkbbgZwH8Aa9uquNGGDoX1b26zzTaVcknSZuMKUiey3Xbb0dDQwNKlSzn99NO5/vrr31Cnrq6Oiy66iNralu9QOGPGDKZPn06/fv0AOOigg/jhD3/I9ttvv9nGLkndRUT8C/BcZt4bEXWt1JsOTAcYMmQI9fX1r3t90KBBrX5QK71703PIEPq88ALx2mtkr178faedWN27N7TWbjPaddddeeaZZ3jmmWf4j//4D66++uo31DnooIP48pe/zIQJE1rs59JLL+XEE09snKcOO+wwrrjiio2ep9asWcPLL7/Mf/7nf7Lddttx+umnb1Q/rVm1atUb/g+3Fg0NDVvt2LcE49Oy7hobE6RO6E1velOzyVG1ZsyYwbHHHts48cyePbu9hrZFZCaZ6W3BJXWSMkwUAAAYlklEQVRWk4GDI+IgoC8wMCJ+kJnHNq2UmTOBmVD5HKT1t6ksXLiw7W1hAwbA0KGNW8i2bb9z2GgDBgxgwIAB/PSnP2329R49etC/f/9Wz+2yyy7jpJNOaqzzq1/9apPGtC4+ffr0oU+fPptlu13fvn0ZP358u/e7JXTXbVLVMj4t666x8S/QzeSzn/0s3/72txufn3vuuVx88cU0NDQwdepUJkyYwJgxY/jZz372hraLFi1i9OjRALzyyiscddRR1NTUcOSRR/LKK6801jvllFOora1l1KhRnHPOOQBccsklLF26lP3224/99tsPgGHDhvHCCy8A8LWvfY3Ro0czevRoZsyY0Xi8ESNGcPLJJzNq1CgOOOCA1x1nnZtvvpm9996b8ePHs//++/Pss88ClXcXTjzxRMaMGUNNTQ033HADALfccgsTJkxg7NixTJ06tTEOF110UWOfo0ePZtGiRY1j+MQnPsGECRNYvHhxs+cHMHfuXN797nczduxY9tprL15++WX22Wcf5s2b11hn8uTJzJ8/v+r/L0mqVmZ+LjN3y8xhwFHAb9dPjrYGXXGeamrevHlMmjSJmpoaPvzhD7N8+fLG448cOZKamhqOOuooAO644w7GjRvHuHHjGD9+fOsre5K6vO6xgvTLs+AvD7T48rZrVkOPDQzFP42BA7/S4stHHXUUn/70p/nEJz4BwHXXXcctt9xC3759ufHGGxk4cCAvvPACkyZN4uCDDyai+duTfuc736Ffv37Mnz+f+fPnv27LwgUXXMAOO+zAmjVrmDp1KvPnz+f000/na1/7Grfffjs77bTT6/q69957ueqqq7j77rvJTPbee2+mTJnC4MGDefTRR/nRj37Ed7/7XT7ykY9www03cOyxr5/v3/Oe93DXXXcREVx++eVceOGFXHzxxZx//vkMGjSIBx6oxHj58uU8//zznHzyycyZM4fhw4ezbNmyNkP6yCOPcNVVVzVO2M2d3x577MGRRx7Jtddey8SJE3nppZfYdtttOemkk/je977HjBkz+NOf/sTf//53ampq2jymJHUKzlPAps9TTR133HF885vfZMqUKZx99tmcd955zJgxg6985Ss8+eST9OnThxUrVgBw0UUXcemllzJ58mQaGhro27dv1WGW1PW4grSZjB8/nueee46lS5dy//33M3jwYN785jeTmXz+85+npqaG/fffn6effrpxJaY5c+bMaZwAampqXvdH/3XXXceECRMYP348CxYs4KGHHmp1TL///e/58Ic/TP/+/dluu+049NBD+d3vfgfA8OHDGTduHAB77rknixYtekP7JUuW8L73vY8xY8bw1a9+lQULFgBw2223ceqppzbWGzx4MHfddRf77rsvw4cPB2CHHXZoM2ZvectbmDRpUqvn98gjj7DrrrsyceJEAAYOHEjPnj054ogj+PnPf85rr73GlVdeyQknnNDm8SRpU2Vm/Wb5DKQtoCvOU+usXLmSFStWMGXKFACOP/545syZ0zjGY445hh/84Af07FlJOidPnsyZZ57JJZdcwooVKxrLJXVP3eM3QCvvoAG8spluD3r44Ydz/fXX85e//KVxGf+aa67h+eef595776VXr14MGzaMVatWtdpPc+/aPfnkk1x00UXMnTuXwYMHc8IJJ7TZT2bLn53Rp0+fxsc9evRoduvCaaedxplnnsnBBx9MfX095557bmO/64+xuTKAnj17srbJBx82HXP//v3bPL+W+u3Xrx/Tpk3jZz/7Gddddx333HNPi+cqSZ2O8xSw6fNUNX7xi18wZ84cbrrpJs4//3wWLFjAWWedxQc+8AFmz57NpEmTuO2229hjD2+lLnVXriBtRkcddRQ//vGPuf766zn88MOByrtau+yyC7169eL222/nqaeearWPfffdl2uuuQaABx98sPG6mpdeeon+/fszaNAgnn32WX75y182thkwYECz+6f33XdffvrTn/K3v/2Nv/71r9x4443ss88+VZ/PypUrGVpuLztr1qzG8gMOOIBvfetbjc+XL1/Ou971Lu644w6efPJJgMYtdsOGDeO+++4D4L777mt8fX0tnd8ee+zB0qVLmTt3LlC5MHf16tUAnHTSSZx++ulMnDixqhUrSeruuto8tc6gQYMYPHhw4+rT1VdfzZQpU1i7di2LFy9mv/3248ILL2TFihU0NDTw+OOPM2bMGD772c9SW1vLww8/vMHHlNR1dI8VpA4yatQoXn75ZYYOHcquu+4KwDHHHMMHP/hBamtrGTduXJvvUJ1yyimceOKJ1NTUMG7cOPbaay8Axo4dy/jx4xk1ahRvfetbmTx5cmOb6dOnc+CBB7Lrrrty++23N5ZPmDCBE044obGPk046ifHjx7e6TaGpc889lyOOOIKhQ4cyadKkxuTmC1/4AqeeeiqjR4+mR48enHPOORx66KHMnDmTQw89lLVr17LLLrvw61//msMOO4zvf//7jBs3jokTJ/KOd7yj2WO1dH69e/fm2muv5bTTTuOVV15h22235bbbbmO77bZjzz33ZODAgZx44olVnY8kdXddbZ5qatasWfzbv/0bf/vb33jrW9/KVVddxZo1azj22GNZuXIlmckZZ5zB9ttvzxe/+EVuv/12evTowciRIznwwAM3+HiSuo5obTl7a1FbW5vrb6lauHAhI0aMqKr9lvgE7q3Z1hKfpUuXUldXx8MPP9ziLcI35PuiWt31FpjVMDat62rxiYh7M7PlD2nrxpynNq8tEZ/NMX9sKV3td017Mz4t62qxqXaecouduoTvf//77L333lxwwQV+fpIkSZI2mlvs1CUcd9xxHHfccR09DEmSJG3luvRb7V1h+6Daj98Pkjobfy9tHfx/krqXLpsg9e3blxdffNFfagIqk9uLL77oh/9J6jScp7YOzh9S99Nlt9jttttuLFmyhOeff77NuqtWrfIXXyu6Snz69u3Lbrvt1tHDkCTAeao9be74OH9I3UuXTZB69erF8OHDq6pbX1/P+PHjN/OItl7GR5Lan/NU+zE+ktpTl91iJ0mSJEkbygRJkiRJkgoTJEmSJEkqTJAkSZIkqTBBkiRJkqTCBEmSJEmSChMkSZIkSSpMkCRJkiSpMEGSJEmSpMIESZIkSZIKEyRJkiRJKkyQJEmSJKkwQZIkSZKkwgRJkiRJkgoTJEmSJEkqTJAkSZIkqagqQYqI90fEIxHxWESc1czrfSLi2vL63RExrJT3joirIuKBiLg/IuqatDm6lM+PiFsiYqdSPi4i7oqIeRFxT0Ts1S5nKkmSJEltaDNBiogewKXAgcBI4OiIGLletY8DyzPzbcDXgf8q5ScDZOYYYBpwcURsExE9gW8A+2VmDTAf+GRpcyFwXmaOA84uzyVJkiRps6tmBWkv4LHMfCIzXwV+DByyXp1DgFnl8fXA1IgIKgnVbwAy8zlgBVALRPnqX+oNBJaW9lmeAwxqUi5JkiRJm1U1CdJQYHGT50tKWbN1MnM1sBLYEbgfOCQiekbEcGBPYPfMfA04BXiASgI0Erii9PVp4KsRsRi4CPjcRpyXJEmSJG2wnlXUiWbKsso6VwIjgHuAp4A7gdUR0YtKgjQeeAL4JpVE6Mul/IzMvCEiPkIlcdr/DYOKmA5MBxgyZAj19fVVnErzGhoaNql9V2d8Wmd8WmZsWmd8JEnqfKpJkJYAuzd5vhtv3Pa2rs6Scn3RIGBZZiZwxrpKEXEn8CgwDiAzHy/l1wHrbv5wPPCp8vh/gMubG1RmzgRmAtTW1mZdXV0Vp9K8+vp6NqV9V2d8Wmd8WmZsWmd8JEnqfKrZYjcXeHtEDI+I3sBRwE3r1bmJSmIDcDjw28zMiOgXEf0BImIasDozHwKeBkZGxM6lzTRgYXm8FJhSHr+XSkIlSZIkSZtdmytImbk6Ij4J3Ar0AK7MzAUR8SXgnsy8ico2uKsj4jFgGZUkCmAX4NaIWEslKfpo6XNpRJwHzImI16hsvzuhtDkZ+EZZiVpF2UYnSZIkSZtbNVvsyMzZwOz1ys5u8ngVcEQz7RYB72yhz8uAy5op/z2VmzlIkiRJ0hZV1QfFSpIkSVJ3YIIkSZIkSYUJkiRJkiQVJkiSJEmSVJggSZIkSVJhgiRJkiRJhQmSJEmSJBUmSJIkSZJUmCBJkiRJUmGCJEmSJEmFCZIkSZIkFSZIkiRJklSYIEmSJElSYYIkSZIkSYUJkiRJkiQVJkiSJG2giOgbEX+MiPsjYkFEnNfRY5IktY+eHT0ASZK2Qn8H3puZDRHRC/h9RPwyM+/q6IFJkjaNCZIkSRsoMxNoKE97la/suBFJktqLW+wkSdoIEdEjIuYBzwG/zsy7O3pMkqRN5wqSJEkbITPXAOMiYnvgxogYnZkPrns9IqYD0wGGDBlCfX39Rh+roaFhk9p3dcandcandcanZd01NiZIkiRtgsxcERH1wPuBB5uUzwRmAtTW1mZdXd1GH6O+vp5Nad/VGZ/WGZ/WGZ+WddfYuMVOkqQNFBE7l5UjImJbYH/g4Y4dlSSpPbiCJEnShtsVmBURPai82XhdZv68g8ckSWoHJkiSJG2gzJwPjO/ocUiS2p9b7CRJkiSpMEGSJEmSpMIESZIkSZIKEyRJkiRJKkyQJEmSJKkwQZIkSZKkwgRJkiRJkgoTJEmSJEkqTJAkSZIkqTBBkiRJkqTCBEmSJEmSChMkSZIkSSpMkCRJkiSpMEGSJEmSpMIESZIkSZIKEyRJkiRJKkyQJEmSJKkwQZIkSZKkwgRJkiRJkgoTJEmSJEkqqkqQIuL9EfFIRDwWEWc183qfiLi2vH53RAwr5b0j4qqIeCAi7o+IuiZtji7l8yPilojYqZRfGxHzyteiiJjXLmcqSZIkSW1oM0GKiB7ApcCBwEjg6IgYuV61jwPLM/NtwNeB/yrlJwNk5hhgGnBxRGwTET2BbwD7ZWYNMB/4ZKl7ZGaOy8xxwA3ATzbxHCVJkiSpKtWsIO0FPJaZT2Tmq8CPgUPWq3MIMKs8vh6YGhFBJaH6DUBmPgesAGqBKF/9S72BwNKmHZbyjwA/2ojzkiRJkqQNVk2CNBRY3OT5klLWbJ3MXA2sBHYE7gcOiYieETEc2BPYPTNfA04BHqCSGI0Erlivz32AZzPz0Q06I0mSJEnaSD2rqBPNlGWVda4ERgD3AE8BdwKrI6IXlQRpPPAE8E3gc8CXm7Q/mlZWjyJiOjAdYMiQIdTX11dxKs1raGjYpPZdnfFpnfFpmbFpnfGRJKnzqSZBWgLs3uT5bqy3Ha5JnSXl+qJBwLLMTOCMdZUi4k7gUWAcQGY+XsqvA85qUq8ncCiVFadmZeZMYCZAbW1t1tXVVXEqzauvr2dT2nd1xqd1xqdlxqZ1xkeSpM6nmi12c4G3R8TwiOgNHAXctF6dm4Djy+PDgd9mZkZEv4joDxAR04DVmfkQ8DQwMiJ2Lm2mAQub9Lc/8HBmLtmos5IkSZKkjdDmClJmro6ITwK3Aj2AKzNzQUR8CbgnM2+icv3Q1RHxGLCMShIFsAtwa0SspZIUfbT0uTQizgPmRMRrVLbfndDksEfhzRkkSZIkbWHVbLEjM2cDs9crO7vJ41XAEc20WwS8s4U+LwMua+G1E6oZlyRJkiS1p6o+KFaSJEmSugMTJEmSJEkqTJAkSZIkqTBBkiRJkqTCBEmSJEmSChMkSZIkSSpMkCRJkiSpMEGSJEmSpMIESZIkSZIKEyRJkiRJKkyQJEmSJKkwQZIkSZKkwgRJkiRJkgoTJEmSJEkqTJAkSZIkqTBBkiRJkqTCBEmSJEmSChMkSZIkSSpMkCRJkiSpMEGSJEmSpMIESZIkSZIKEyRJkjZQROweEbdHxMKIWBARn+roMUmS2kfPjh6AJElbodXAv2fmfRExALg3In6dmQ919MAkSZvGFSRJkjZQZj6TmfeVxy8DC4GhHTsqSVJ7cAVJkqRNEBHDgPHA3euVTwemAwwZMoT6+vqNPkZDQ8Mmte/qjE/rjE/rjE/LumtsTJAkSdpIEbEdcAPw6cx8qelrmTkTmAlQW1ubdXV1G32c+vp6NqV9V2d8Wmd8Wmd8WtZdY9PtE6Tzbl7AnQ+9wnce+UNHD6XTWrHC+LTG+LTM2LSus8Vn5JsGcs4HR3X0MLYaEdGLSnJ0TWb+pKPHI0lqH16DJEnSBoqIAK4AFmbm1zp6PJKk9tPtV5DO+eAo6gc8T13duzp6KJ1WZXnV+LTE+LTM2LTO+GzVJgMfBR6IiHml7POZObsDxyRJagfdPkGSJGlDZebvgejocUiS2p9b7CRJkiSpMEGSJEmSpMIESZIkSZIKEyRJkiRJKkyQJEmSJKkwQZIkSZKkwgRJkiRJkgoTJEmSJEkqTJAkSZIkqTBBkiRJkqQiMrOjx7DJIuJ54KlN6GIn4IV2Gk5XZHxaZ3xaZmxa19Xi85bM3LmjB9EZOU9tdsandcandcanZV0tNlXNU10iQdpUEXFPZtZ29Dg6K+PTOuPTMmPTOuOjavm90jrj0zrj0zrj07LuGhu32EmSJElSYYIkSZIkSYUJUsXMjh5AJ2d8Wmd8WmZsWmd8VC2/V1pnfFpnfFpnfFrWLWPjNUiSJEmSVLiCJEmSJElFt0+QIuL9EfFIRDwWEWd19Hg6k4jYPSJuj4iFEbEgIj7V0WPqbCKiR0T8v4j4eUePpbOJiO0j4vqIeLh8D72ro8fUmUTEGeXn6sGI+FFE9O3oMalzcp5qmfNU25ynWuY81bruPE916wQpInoAlwIHAiOBoyNiZMeOqlNZDfx7Zo4AJgGnGp83+BSwsKMH0Ul9A7glM/cAxmKcGkXEUOB0oDYzRwM9gKM6dlTqjJyn2uQ81TbnqZY5T7Wgu89T3TpBAvYCHsvMJzLzVeDHwCEdPKZOIzOfycz7yuOXqfziGNqxo+o8ImI34APA5R09ls4mIgYC+wJXAGTmq5m5omNH1en0BLaNiJ5AP2BpB49HnZPzVCucp1rnPNUy56mqdNt5qrsnSEOBxU2eL8FfrM2KiGHAeODujh1JpzID+A9gbUcPpBN6K/A8cFXZ2nF5RPTv6EF1Fpn5NHAR8GfgGWBlZv6qY0elTsp5qkrOU81ynmqZ81Qruvs81d0TpGimzNv6rScitgNuAD6dmS919Hg6g4j4F+C5zLy3o8fSSfUEJgDfyczxwF8Br50oImIwlVWA4cCbgP4RcWzHjkqdlPNUFZyn3sh5qk3OU63o7vNUd0+QlgC7N3m+G91o+bAaEdGLyqRzTWb+pKPH04lMBg6OiEVUtry8NyJ+0LFD6lSWAEsyc907uddTmYhUsT/wZGY+n5mvAT8B3t3BY1Ln5DzVBuepFjlPtc55qnXdep7q7gnSXODtETE8InpTufjspg4eU6cREUFlb+7CzPxaR4+nM8nMz2Xmbpk5jMr3zW8zs9u8s9KWzPwLsDgi3lmKpgIPdeCQOps/A5Miol/5OZuKFwerec5TrXCeapnzVOucp9rUreepnh09gI6Umasj4pPArVTuznFlZi7o4GF1JpOBjwIPRMS8Uvb5zJzdgWPS1uM04JryR90TwIkdPJ5OIzPvjojrgfuo3IXr/9FNP61crXOeapPzlDaF81QLuvs8FZluZZYkSZIkcIudJEmSJDUyQZIkSZKkwgRJkiRJkgoTJEmSJEkqTJAkSZIkqTBBkrYSEVEXET/v6HFIktQc5yl1FSZIkiRJklSYIEntLCKOjYg/RsS8iPjviOgREQ0RcXFE3BcRv4mInUvdcRFxV0TMj4gbI2JwKX9bRNwWEfeXNv9cut8uIq6PiIcj4pry6daSJFXNeUpqnQmS1I4iYgRwJDA5M8cBa4BjgP7AfZk5AbgDOKc0+T7w2cysAR5oUn4NcGlmjgXeDTxTyscDnwZGAm+l8inykiRVxXlKalvPjh6A1MVMBfYE5pY3zbYFngPWAteWOj8AfhIRg4DtM/OOUj4L+J+IGAAMzcwbATJzFUDp74+ZuaQ8nwcMA36/+U9LktRFOE9JbTBBktpXALMy83OvK4z44nr1so0+WvL3Jo/X4M+wJGnDOE9JbXCLndS+fgMcHhG7AETEDhHxFio/a4eXOv/6/7drhygRQEEYgP+xLIg38QzeYYtxEbNXMO0p9Co2wWo1muyyoskwBgcs4pZlheX74oThTRp+5iV56O5NkteqOpv6Ksl9d78leamq5fRYVNXxXqcA4FDZU7CFVA871N1PVXWd5K6qjpJ8JrlK8pHktKoek2zy/f87SS6S3MxieU5yOfVVktuqWk+P8z2OAcCBsqdgu+r+64IK7EJVvXf3yX+/AwB+Y0/BD1/sAAAAhgsSAADAcEECAAAYAhIAAMAQkAAAAIaABAAAMAQkAACAISABAACML7yCIXeMllIMAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11f8ca390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Zero_Init\n",
    "neural_net = NN(hidden_dims=(500, 400),\n",
    "                n_hidden=2,                  # number of hidden layers\n",
    "                mode='train',                # current mode : train/test\n",
    "                datapath=\"mnist.npy\",        # path where to find the .pkl file\n",
    "                model_path=None,             # path where to save/load the model \n",
    "                epsilon = 1e-8,              # for cross entropy calculus stability : log(x) = log(epsilon) if x < epsilon\n",
    "                lr = 5e-1,                   # learning rate\n",
    "                n_epochs = 10,               # max number of epochs\n",
    "                batch_size = 100,            # batch size for training\n",
    "                compute_biases = True,       # whether biases are used or not\n",
    "                init_method = \"zero\")        # initialization method\n",
    "_,_ = neural_net.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**- Initialization with a Standard Normal distribution:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Normal init\n",
    "neural_net = NN(hidden_dims=(500, 400),\n",
    "                n_hidden=2,                  # number of hidden layers\n",
    "                mode='train',                # current mode : train/test\n",
    "                datapath=\"mnist.pkl\",        # path where to find the .pkl file\n",
    "                model_path=None,             # path where to save/load the model \n",
    "                epsilon = 1e-8,              # for cross entropy calculus stability : log(x) = log(epsilon) if x < epsilon\n",
    "                lr = 5e-1,                   # learning rate\n",
    "                n_epochs = 10,               # max number of epochs\n",
    "                batch_size = 100,            # batch size for training\n",
    "                compute_biases = True,       # whether biases are used or not\n",
    "                init_method = \"normal\")      # initialization method\n",
    "normal_hist_acc, normal_hist_loss = neural_net.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**- Initialization with Glorot method:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Glorot_Init\n",
    "neural_net = NN(hidden_dims=(500, 400),\n",
    "                n_hidden=2,                  # number of hidden layers\n",
    "                mode='train',                # current mode : train/test\n",
    "                datapath=\"mnist.npy\",        # path where to find the .pkl file\n",
    "                model_path=None,             # path where to save/load the model \n",
    "                epsilon = 1e-8,              # for cross entropy calculus stability : log(x) = log(epsilon) if x < epsilon\n",
    "                lr = 5e-1,                   # learning rate\n",
    "                n_epochs = 10,               # max number of epochs\n",
    "                batch_size = 100,            # batch size for training\n",
    "                compute_biases = True,       # whether biases are used or not\n",
    "                init_method = \"glorot\")      # initialization method\n",
    "glorot_hist_acc, glorot_hist_loss = neural_net.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.2) Compare the three setups by plotting the losses against the training time (epoch) and comment on the result.**\n",
    "\n",
    "- Zero initialization for the weights leads to no change at all in accuracy. We can indeed show that doing so will lead to no possible update of the weights during the retropropagation, as\n",
    "\n",
    "$$\n",
    "\\nabla H_{i-1} = \\nabla A_i \\nabla W_i^T\n",
    "$$\n",
    "\n",
    "will give zero gradients. Actually, only the biases of the last layer will be changed according to\n",
    "\n",
    "$$\n",
    "\\nabla A_{L+1} = -(\\mbox{true labels} - H_{L+1})\\\\\n",
    "\\mbox{and}\\\\\n",
    "\\nabla db_i = \\mbox{mean over batch dimension}(\\nabla A_i)\n",
    "$$\n",
    "\n",
    "in such a way that will not impact the predictions over each example from an epoch to another.\n",
    "\n",
    "- If we simply generate the weights following a normal distribution $N(0,1)$, this leads to quick numeric explosion and errors. Indeed, weights will add up and are likely to lead to exponential overflows (or zero divisions in our stabilized softmax). We chose to tackle this issue by dividing the normal weights by the dimension of the previous layer. This way, preactivation values will stay around \\[-1,1\\] at each layer. After 10 epochs, this initialization method leads to a 91% accuracy and no overfitting (the model needs to train more).\n",
    "\n",
    "- If we use the formula from Glorot, Bengio - 2010, we observe extremely fast convergence as the validation accuracy reaches 96% after the first epoch (versus 48% for normal initialization) and the model starts overfitting (regarding the cross-entropy loss) at more than 98% accuracy after only 7 epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Hyperparameter Search\n",
    "\n",
    "**3.1) Find out a combination of hyper-parameters (model architecture, learning rate, nonlinearity, etc.) such that the average accuracy rate on the validation set ($r^{(valid)}$) is at least 97\\%.**\n",
    "\n",
    "Although we have found a model that performs better than 98% relatively quickly by hand, in this part we perform a random search in hope to find a better model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomSearch:\n",
    "    \n",
    "    def __init__(self, model, params, n_itters, seed = 42):\n",
    "        self.params = params # parameters assignation grid (dictionary)\n",
    "        self.n_itters = n_itters # number of searches\n",
    "        self.model = model # NN class to use for random search\n",
    "        self.seed = seed # seed for reproducibility\n",
    "        \n",
    "    def run(self):\n",
    "\n",
    "        #np.random.seed(self.seed)\n",
    "        results = []\n",
    "        best_acc = None\n",
    "        best_loss = None\n",
    "        params = [p for p in self._generate_grid()]\n",
    "        for it, selected_params in enumerate(params):\n",
    "            try:\n",
    "                print(f\"{it}\",\"-\".join(map(lambda x: str(x),selected_params.items())))\n",
    "                instance_model = self.model(seed = self.seed,**selected_params)\n",
    "                acc, loss = instance_model.train(show_graph=False,save_model=False)\n",
    "                id_best = np.argmin(loss[\"validation loss\"])\n",
    "\n",
    "                results.append((selected_params, loss[\"validation loss\"][id_best], acc[\"validation accuracy\"][id_best]))\n",
    "\n",
    "                if best_acc is None or best_loss> loss[\"validation loss\"][id_best]:\n",
    "                    print(f\"Found a better model: Accuracy from {best_acc} to {acc['validation accuracy'][id_best]}\")\n",
    "                    best_loss = loss[\"validation loss\"][id_best]\n",
    "                    best_acc  = acc[\"validation accuracy\"][id_best]\n",
    "                print(f'Model {it+1}, accuracy {acc[\"validation accuracy\"][id_best]:.5f}, loss {loss[\"validation loss\"][id_best]:.5f}, Best Model: acc {best_acc:.5f}, loss {best_loss:.5f}')\n",
    "            except KeyboardInterrupt:\n",
    "                break\n",
    "        return results\n",
    "    \n",
    "    def _generate_grid(self):\n",
    "        for it in range(self.n_itters):\n",
    "            yield self._select_params()\n",
    "    def _select_params(self):\n",
    "        selected_params = {}\n",
    "        for key,value in self.params.items():\n",
    "            if key == \"hidden_dims\":\n",
    "                continue\n",
    "            elif key == \"n_hidden\":\n",
    "                assert type(value) == int and value>0\n",
    "                hidden_units = []\n",
    "                for _ in range(value):\n",
    "                    hidden_units.append(np.random.choice(self.params[\"hidden_dims\"]))\n",
    "                selected_params[\"hidden_dims\"] = hidden_units\n",
    "                selected_params[key]=value\n",
    "            elif type(value)==list or type(value)==tuple:\n",
    "                selected_params[key] = np.random.choice(self.params[key])\n",
    "            else:\n",
    "                selected_params[key]=value\n",
    "        return selected_params\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ('hidden_dims', [600, 400])-('n_hidden', 2)-('lr', 0.5)-('n_epochs', 10)-('batch_size', 125)-('activation', 'tanh')-('datapath', 'mnist.npy')\n",
      "Found a better model: Accuracy from None to 0.9773\n",
      "Model 1, accuracy 0.97730, loss 0.08203, Best Model: acc 0.97730, loss 0.08203\n",
      "1 ('hidden_dims', [500, 400])-('n_hidden', 2)-('lr', 0.5)-('n_epochs', 20)-('batch_size', 75)-('activation', 'sigmoid')-('datapath', 'mnist.npy')\n",
      "Model 2, accuracy 0.96310, loss 0.13616, Best Model: acc 0.97730, loss 0.08203\n",
      "2 ('hidden_dims', [400, 600])-('n_hidden', 2)-('lr', 0.5)-('n_epochs', 10)-('batch_size', 75)-('activation', 'sigmoid')-('datapath', 'mnist.npy')\n",
      "Model 3, accuracy 0.95220, loss 0.17978, Best Model: acc 0.97730, loss 0.08203\n",
      "3 ('hidden_dims', [600, 400])-('n_hidden', 2)-('lr', 0.5)-('n_epochs', 15)-('batch_size', 100)-('activation', 'sigmoid')-('datapath', 'mnist.npy')\n",
      "Model 4, accuracy 0.95080, loss 0.18353, Best Model: acc 0.97730, loss 0.08203\n",
      "4 ('hidden_dims', [600, 400])-('n_hidden', 2)-('lr', 0.7)-('n_epochs', 10)-('batch_size', 75)-('activation', 'relu')-('datapath', 'mnist.npy')\n",
      "Found a better model: Accuracy from 0.9773 to 0.9801\n",
      "Model 5, accuracy 0.98010, loss 0.06664, Best Model: acc 0.98010, loss 0.06664\n",
      "5 ('hidden_dims', [500, 600])-('n_hidden', 2)-('lr', 0.3)-('n_epochs', 10)-('batch_size', 100)-('activation', 'tanh')-('datapath', 'mnist.npy')\n",
      "Model 6, accuracy 0.97520, loss 0.08380, Best Model: acc 0.98010, loss 0.06664\n",
      "6 ('hidden_dims', [600, 600])-('n_hidden', 2)-('lr', 0.3)-('n_epochs', 10)-('batch_size', 125)-('activation', 'relu')-('datapath', 'mnist.npy')\n",
      "Model 7, accuracy 0.97870, loss 0.06985, Best Model: acc 0.98010, loss 0.06664\n",
      "7 ('hidden_dims', [400, 500])-('n_hidden', 2)-('lr', 0.7)-('n_epochs', 15)-('batch_size', 125)-('activation', 'sigmoid')-('datapath', 'mnist.npy')\n",
      "Model 8, accuracy 0.95590, loss 0.16631, Best Model: acc 0.98010, loss 0.06664\n",
      "8 ('hidden_dims', [400, 400])-('n_hidden', 2)-('lr', 0.3)-('n_epochs', 15)-('batch_size', 100)-('activation', 'tanh')-('datapath', 'mnist.npy')\n",
      "Model 9, accuracy 0.97880, loss 0.07130, Best Model: acc 0.98010, loss 0.06664\n",
      "9 ('hidden_dims', [600, 400])-('n_hidden', 2)-('lr', 0.3)-('n_epochs', 10)-('batch_size', 125)-('activation', 'relu')-('datapath', 'mnist.npy')\n",
      "Model 10, accuracy 0.97880, loss 0.07192, Best Model: acc 0.98010, loss 0.06664\n"
     ]
    }
   ],
   "source": [
    "grid_params = {\n",
    "    \"hidden_dims\":[400,500,600],\n",
    "    \"n_hidden\":2,\n",
    "    \"lr\":[.3,.5,.7],\n",
    "    \"n_epochs\":[10,15,20],\n",
    "    \"batch_size\":[75,100,125],\n",
    "    \"activation\":[\"tanh\",\"sigmoid\",\"relu\"],\n",
    "    \"datapath\":\"mnist.npy\",\n",
    "}\n",
    "\n",
    "rd_search = RandomSearch(\n",
    "    model = NN,\n",
    "    params = grid_params,\n",
    "    n_itters = 10\n",
    ")\n",
    "experiments = rd_search.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hidden_dims</th>\n",
       "      <th>n_hidden</th>\n",
       "      <th>lr</th>\n",
       "      <th>n_epochs</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>activation</th>\n",
       "      <th>datapath</th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[600, 400]</td>\n",
       "      <td>2</td>\n",
       "      <td>0.7</td>\n",
       "      <td>10</td>\n",
       "      <td>75</td>\n",
       "      <td>relu</td>\n",
       "      <td>mnist.npy</td>\n",
       "      <td>0.066636</td>\n",
       "      <td>0.9801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[400, 400]</td>\n",
       "      <td>2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>15</td>\n",
       "      <td>100</td>\n",
       "      <td>tanh</td>\n",
       "      <td>mnist.npy</td>\n",
       "      <td>0.071301</td>\n",
       "      <td>0.9788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[600, 400]</td>\n",
       "      <td>2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>10</td>\n",
       "      <td>125</td>\n",
       "      <td>relu</td>\n",
       "      <td>mnist.npy</td>\n",
       "      <td>0.071917</td>\n",
       "      <td>0.9788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[600, 600]</td>\n",
       "      <td>2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>10</td>\n",
       "      <td>125</td>\n",
       "      <td>relu</td>\n",
       "      <td>mnist.npy</td>\n",
       "      <td>0.069855</td>\n",
       "      <td>0.9787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[600, 400]</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10</td>\n",
       "      <td>125</td>\n",
       "      <td>tanh</td>\n",
       "      <td>mnist.npy</td>\n",
       "      <td>0.082031</td>\n",
       "      <td>0.9773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[500, 600]</td>\n",
       "      <td>2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>tanh</td>\n",
       "      <td>mnist.npy</td>\n",
       "      <td>0.083797</td>\n",
       "      <td>0.9752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[500, 400]</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>20</td>\n",
       "      <td>75</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>mnist.npy</td>\n",
       "      <td>0.136157</td>\n",
       "      <td>0.9631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[400, 500]</td>\n",
       "      <td>2</td>\n",
       "      <td>0.7</td>\n",
       "      <td>15</td>\n",
       "      <td>125</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>mnist.npy</td>\n",
       "      <td>0.166307</td>\n",
       "      <td>0.9559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[400, 600]</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10</td>\n",
       "      <td>75</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>mnist.npy</td>\n",
       "      <td>0.179784</td>\n",
       "      <td>0.9522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[600, 400]</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>15</td>\n",
       "      <td>100</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>mnist.npy</td>\n",
       "      <td>0.183532</td>\n",
       "      <td>0.9508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  hidden_dims  n_hidden   lr  n_epochs  batch_size activation   datapath  \\\n",
       "4  [600, 400]         2  0.7        10          75       relu  mnist.npy   \n",
       "8  [400, 400]         2  0.3        15         100       tanh  mnist.npy   \n",
       "9  [600, 400]         2  0.3        10         125       relu  mnist.npy   \n",
       "6  [600, 600]         2  0.3        10         125       relu  mnist.npy   \n",
       "0  [600, 400]         2  0.5        10         125       tanh  mnist.npy   \n",
       "5  [500, 600]         2  0.3        10         100       tanh  mnist.npy   \n",
       "1  [500, 400]         2  0.5        20          75    sigmoid  mnist.npy   \n",
       "7  [400, 500]         2  0.7        15         125    sigmoid  mnist.npy   \n",
       "2  [400, 600]         2  0.5        10          75    sigmoid  mnist.npy   \n",
       "3  [600, 400]         2  0.5        15         100    sigmoid  mnist.npy   \n",
       "\n",
       "       loss  accuracy  \n",
       "4  0.066636    0.9801  \n",
       "8  0.071301    0.9788  \n",
       "9  0.071917    0.9788  \n",
       "6  0.069855    0.9787  \n",
       "0  0.082031    0.9773  \n",
       "5  0.083797    0.9752  \n",
       "1  0.136157    0.9631  \n",
       "7  0.166307    0.9559  \n",
       "2  0.179784    0.9522  \n",
       "3  0.183532    0.9508  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "output = defaultdict(list)\n",
    "for obs in experiments:\n",
    "    for key,val in obs[0].items():\n",
    "        output[key].append(val)\n",
    "    output[\"loss\"].append(obs[1])\n",
    "    output[\"accuracy\"].append(obs[2])\n",
    "\n",
    "import pandas as pd\n",
    "sorted_output= pd.DataFrame(output)\n",
    "sorted_output.sort_values(by=\"accuracy\",ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
